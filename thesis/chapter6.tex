%----------------------------------------------------------------------------
\chapter{Problems, possible improvements}
%----------------------------------------------------------------------------
The implementation that is described in this paper works quite well, but the goal of development was not to create an optimized, efficient algorithm but to create something that is easy to understand and to use.

This means that while the examples show that the basic functions work properly, there might be ways to improve on the speed of the algorithms.
\begin{itemize}
\item The First and Follow sets are calculated iteratively. While this is a simple-to-understand algorithm, it is not the most efficient --- in fact a lot of set unions are recalculated a lot of times, which makes this algorithm rather wasteful. In the future, better, more efficient algorithms \cite{deremer1982efficient} could be used to calculate these sets.
\item The LALR parser generator algorithm first generates the items sets and the extended grammar for the LR(\textit{1}) parser table, and only reduces the table size while calculating the Action/Goto table. This could be improved upon by merging during the calculation of the item sets, as mentioned in Chapter 3.2.2.
\end{itemize}

Another problem is that the current implementation only accepts LALR grammars. While this is not a severe limitation as simple languages, or subsets of proper programming languages (or even full programming languages like Java \cite{joy2000java}) can be implemented using LALR grammars, there are programming languages that have a non-LALR grammar, like C++ \cite{willink2001meta}. This problem could be solved by implementing other parsing algorithms, and providing the possibility for the module writer of choosing the algorithm they want to use.

Some improvements could be made in the area of error handling. Currently if an unexpected symbol is encountered by the parser, it throws a syntax error, that has information about which line and which token in the line caused the error. This however does not mean that an exact character position for the error can be determined, since tokens can have length larger than one character, and in the default case whitespaces are skipped, which means information about their length is lost. Improving this would make writing a web based programming editor for the interpreter easier.